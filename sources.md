# Sources, pseudoscience, and alternative medicine
Any type of DIY speculation about things like psychiatry runs the risk of being [pseudoscience](https://en.wikipedia.org/wiki/Pseudoscience). I suspect I straddle that line a little, for a few reasons:

1. Things that work for me may not work for most other people with the same apparent condition (i.e. we may have a different latent condition or genetic disposition)
2. I have different goals than many people who want to treat psychiatric disorders, particularly around risks
3. I often deliberately avoid the most effective treatments, as they tend to bypass the most homeostatic regulation mechanisms
4. Medical studies are undergoing a reproducibility crisis, which impacts certain subfields more than others and isn't an excuse to disregard science or results blindly

Here are some examples of these biases.

I have an MTHFR mutation, so a lot of my treatment focuses on preventing homocysteine buildup. This is questionable in medical science; I haven't had any bloodwork done to suggest that I have a problem with homocysteine, nor that my methylation is deficient. I suspect it because I felt much better after taking methylfolate once, and have a history of relevant risk factors like coffee and alcohol use. But I didn't study this in detail; I use methylfolate because it works _for me_ -- then I retroactively speculate about why it worked and see it's likely to create problems. That isn't science, it's post-hoc justification -- and that's ok with me because I'm after quality of life more than quality of research.

(2), (3), and (4) are more interesting and deserve their own sections. First, though, a quick aside about reliability in case it's helpful:


## Finding reliable sources
Wikipedia is great but doesn't have everything. I often end up consulting other websites like [Drugs.com](https://drugs.com) for supplemental information.

I've found [MediaBiasFactCheck.com](https://mediabiasfactcheck.com) to be pretty reliable for determining whether a source is accurate. I occasionally think they may be a little off, for example with [PsychologyToday](https://mediabiasfactcheck.com/psychology-today), which I wonder about sometimes. But overall I think their assessment of sources is pretty accurate and I tend to trust them. I also think it's worth reading [their wikipedia page](https://en.wikipedia.org/wiki/Media_Bias/Fact_Check) for context.

If you know of a better fact-checking strategy, I'd like to hear about it. This is something I haven't thought about as much as I probably should.


## Spencer vs the psychiatric institution
I have a beef. My expectation is that doctors view me being a potato as better than me being a hyperproductive genius but having a 10% chance of suicide, and I disagree with that assessment. I value my ability to think and at some point I'm willing to roll the dice, probably more than the medical institution would like me to. That's my prerogative because I don't owe life to anyone.

What that means, though, is that I'm not necessarily going to avoid hypomania as assiduously as bipolar medication regimes tend to (despite that being the most effective way to prevent suicide, numerically speaking). In fact, I value hypomania to some extent because it makes me extremely productive. I'd much rather be able to support consistent hypomania, have some workarounds in place for problem-mania, and avoid depression altogether even though I understand that this probably increases my risk of suicide overall. I'm more interested in living well than living predictably.

I think the medical institution should provide alternatives to the safety-first approach, and not just for me. Studies vary, but something like 60% of bipolar patients are medically noncompliant after two years. This is shockingly bad; if 60% of people stopped wearing seatbelts after two years, we'd ask ourselves how the hell we screwed it up so much. Bipolar is a more complicated problem, of course, but stuff like microdosing OTC lithium and [substituting GABA-ergic supplements for alcohol](alcohol-substitution.md) should be common wisdom in my opinion, especially for people with a history of mental problems.


## Back to reliable sources: doctors
I think America's medical instutition is widely misunderstood.

**TODO:** bitch less, rationalize more -- the real position here is that drugs are legal (behind the medical paywall), which effectively splits the cartel supply and adds a substantial layer of regulation + expertise, not all of which is bad; it just requires some management (or something along those lines)

...also, quick rant, I really don't like the fact that drug companies and drug cartels have nearly identical incentives and sell nearly the same set of stuff. I'm not crazy here, right? Like the [opioid crisis](https://en.wikipedia.org/wiki/Opioid_epidemic_in_the_United_States): that's consistent with what you'd expect if pharmaceutical companies want to maximize shareholder value. I'm not saying doctors or pharmaceutical companies are evil or unknowledgeable or involved in a conspiracy; I'm just surprised that people don't expect more transparency. **Given the obvious conflicts of interest between you and your doctor, I think it's perfectly reasonable demand a solid explanation behind any non-generic medicine being prescribed to you,** including long-term side effects, mechanism of action, addiction and withdrawal, alternatives, manufacturer, and really anything else you can think of. There are also databases like [ProPublica dollars for docs](https://projects.propublica.org/docdollars/) where you can search for payments between pharmaceutical suppliers and doctors to see if your doctor is prescibing you stuff sold by one of their donors. It seems insane to me that you would have to think about this, but apparently you do.


## Efficacy studies and homeostatic regulation
My second beef, this time with the way treatment efficacy is reported in literature -- or more specifically, why the most effective treatment can create problems for homeostasis by failing to address the root cause.

Let's take [ADHD](https://en.wikipedia.org/wiki/Attention_deficit_hyperactivity_disorder) as an example, and let's suppose the suspected cause is [low dopaminergic functioning](https://en.wikipedia.org/wiki/Attention_deficit_hyperactivity_disorder#Genetics). From a clinical perspective, [NDRIs](https://en.wikipedia.org/wiki/Norepinephrine%E2%80%93dopamine_reuptake_inhibitor) are considered highly effective. Rather than increasing dopamine production, they [prevent dopamine reuptake](https://en.wikipedia.org/wiki/Reuptake_inhibitor) -- that is, the same level of dopamine production will result in a higher steady-state level in the brain.

It's easy to see why this works: your brain has very few ways to screw it up, no matter how pathological your dopamine production pipeline is. The flip side is that your brain also has very few ways to downregulate dopamine in the presence of an NDRI, nor is it likely to upregulate the production pipeline given persistently elevated levels. In other words, NDRIs seem to me like a last-resort kind of solution that makes sense when homeostatic regulation is a lost cause.

I have no doubt that some people have this problem and need NDRIs, but I don't want to assume that about myself. I'd rather assume that various enzymes are compromised and try supplementing precursors like tyrosine to see if I can fix it on the production side. That way I don't end up with a brain that has decreased receptor sites as its last-resort downregulation mechanism, which I suspect would result in withdrawal issues -- especially if I do something else later that fixes the production pathway.

The approach I describe will have lower measured efficacy than direct treatments like NDRIs _for the general population_. It relies on additional conditional variables that most studies don't measure, possibly because most patients don't have their genes sequenced before they go in for treatment (and even if they did, there are probably higher-order metabolic interactions that complicate the picture). I don't think it's antiscientific for me to experiment with and use alternative treatments, but I do think it would be antiscientific for doctors to recommend them without a study that justifies their efficacy for the population in question.

(I hate to point to publication bias, by the way, because I'm implicitly suggesting that we should change our prior expectations of efficacy to adjust for something we're guessing about. That's obviously a bad methodology because you can confirm whatever you want to. I'm willing to use it because I think I can outperform general-population medical studies by experimentation, but it's still bad science from a methodological perspective.)

Also, in case it's unclear, I don't think it's fair to downgrade treatment options just because they're found to be broadly effective -- like that means they compromise homeostasis by default. That's obviously absurd. I think the right approach is to try to understand _why_ a treatment works and consider the big-picture cost/benefit profile.


## The replication crisis, and why I largely ignore it
[There's a replication crisis](https://en.wikipedia.org/wiki/Replication_crisis) affecting social sciences and medical studies. I don't consider this to be a reason to discount science or medicine because alternatives are much worse. It's more about being proactively aware of potential conflicts of interest in study design and trying to understand the mechanisms behind effects that have been observed to see if it passes a sanity check.

I also don't want to understate how serious the replication crisis is for reliability purposes. Numbers vary, but Wikipedia currently describes [reproducibility in medicine](https://en.wikipedia.org/wiki/Replication_crisis#In_medicine) this way (emphasis mine):

> Out of 49 medical studies from 1990–2003 with more than 1000 citations, 45 claimed that the studied therapy was effective. Out of these studies, 16% were contradicted by subsequent studies, 16% had found stronger effects than did subsequent studies, 44% were replicated, and 24% remained largely unchallenged. The US Food and Drug Administration in 1977–1990 found flaws in 10–20% of medical studies. In a paper published in 2012, Glenn Begley, a biotech consultant working at Amgen, and Lee Ellis, at the University of Texas, found that only 11% of 53 pre-clinical cancer studies could be replicated. **The irreproducible studies had a number of features in common, including that studies were not performed by investigators blinded to the experimental versus the control arms, there was a failure to repeat experiments, a lack of positive and negative controls, failure to show all the data, inappropriate use of statistical tests and use of reagents that were not appropriately validated.**

A nontrivial amount of the controversy involves cancer treatments, whose conflict-of-interest profile is pretty different from psychiatric medicine -- especially supplement-based. But it's worth looking out for studies that have questionable features.

For example, I'll go through how I would evaluate [this study on gotu kola and acoustic startle response](https://pubmed.ncbi.nlm.nih.gov/11106141/), which I found after drafting the [strategy section](strategy.md):

+ Conflicts of interest
  + Gotu kola is unregulated, so there's no regulatory incentive to conclude efficacy (good)
  + Gotu kola is a traditional herb that isn't patented, so supply chains have no artificial price inflation (good)
  + Gotu kola isn't the leading product for any company I know of, so I don't think it's going to figure into anyone's sales strategy in an outsized way (good)
  + Traditional medicines are often debunked by studies, so I doubt any researcher is going to tip the scales in favor (good)
  + The sample size is tiny, N = 40, which suggests there wasn't a lot of money that went into it (probably good)
+ Study structure
  + Double-blind (good)
  + Placebo-controlled (good)
  + Concrete hypothesis about receptor bindings up front (good), but some studies have been rewritten after the fact to look this way -- that's part of the replication crisis
  + Prior evidence with mice (good; mice are basically people so this study is pretty redundant)
  + Not-huge sample size (meh)
+ Supporting evidence
  + [CKK receptors](https://en.wikipedia.org/wiki/Cholecystokinin) do in fact relate to anxiety (good)
  + [Wikipedia](https://en.wikipedia.org/wiki/Centella_asiatica) doesn't mention any mechanism of action (meh, but pretty standard for traditional medicines)
+ Reporting
  + "Significantly" without any quantity or p-value attached (bad -- although I suspect/hope the full text has numbers)
  + Measurement methodology is hinted at but not described in detail (meh, although I assume the full text addresses this)
  + Onset and duration are included (good, so I can try it myself)
  + Dosage is included (good, so I can try it)
